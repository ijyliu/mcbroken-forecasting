{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STL and ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'mcbroken-forecasting (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "import numpy as np\n",
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read excel in ../Data/Clean_McBroken_Daily.xlsx\n",
    "df = pd.read_excel('../Data/Clean_McBroken_Daily.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STL and ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing and outlier cases\n",
    "print('Missing cases:', df['Revenue Losses'].isnull().sum())\n",
    "# Mark missing cases\n",
    "df['Missing'] = df['Revenue Losses'].isnull()\n",
    "print('Outlier cases:', df['Outlier'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set missing and outlier cases to the mean of the data - we will use exogenous regressors to de facto remove them later\n",
    "df['Revenue Losses'] = df['Revenue Losses'].fillna(df['Revenue Losses'].mean())\n",
    "df['Revenue Losses'] = df['Revenue Losses'].mask(df['Outlier'], df['Revenue Losses'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Date', 'Revenue Losses', 'Train', 'Missing', 'Outlier']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of indicators for each row to indicate whether the row is an outlier\n",
    "outlier_cols = []\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'Outlier'] == 1:\n",
    "        df['Outlier_' + str(df['Date'][i])] = [1 if j == i else 0 for j in range(len(df))]\n",
    "        outlier_cols.append('Outlier_' + str(df['Date'][i]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of indicators for each row to indicate whether the row is missing\n",
    "missing_cols = []\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'Missing'] == 1:\n",
    "        df['Missing_' + str(df['Date'][i])] = [1 if j == i else 0 for j in range(len(df))]\n",
    "        outlier_cols.append('Missing_' + str(df['Date'][i]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_df = df.query('Train == 1').reset_index(drop=True)\n",
    "test_df = df.query('Train == 0').reset_index(drop=True)\n",
    "print(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ARIMA model using pmdarima's auto_arima\n",
    "n = len(train_df)\n",
    "model = auto_arima(train_df['Revenue Losses'], X=train_df[outlier_cols + missing_cols], seasonal=True, suppress_warnings=True)\n",
    "model.fit(train_df['Revenue Losses'], X=train_df[outlier_cols + missing_cols])\n",
    "\n",
    "# Forecast future values with the fitted model\n",
    "forecast_steps =30\n",
    "\n",
    "# Get the forecast for the future steps with exogenous variables\n",
    "forecast_df = test_df[outlier_cols + missing_cols]\n",
    "forecast_values, conf_int = model.predict(n_periods=forecast_steps, X=forecast_df, return_conf_int=True)\n",
    "# Create a Pandas Series for the forecast and confidence intervals\n",
    "forecast_series = pd.Series(forecast_values, index=test_df.index)\n",
    "lower_series = pd.Series(conf_int[:, 0], index=test_df.index)\n",
    "upper_series = pd.Series(conf_int[:, 1], index=test_df.index)\n",
    "\n",
    "# Retrieve the index for forecasting\n",
    "forecast_start = str(list(df.index)[-1] + pd.DateOffset(1)).split(' ')[0]\n",
    "forecast_index = pd.date_range(start=forecast_start, periods=forecast_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check residuals\n",
    "def plot_arima_residuals(fit, lags=10, bins=20):\n",
    "    \"\"\"\n",
    "    Generates and displays a suite of residual plots for ARIMA models \n",
    "    fitted using pmdarima's auto_arima.\n",
    "\n",
    "    Args:\n",
    "        fit: The fitted ARIMA model object from pmdarima's auto_arima.\n",
    "        lags: Number of lags to plot in the ACF.\n",
    "        bins: Number of bins for the histogram.\n",
    "    \"\"\"\n",
    "\n",
    "    residuals = fit.resid()  # Use fit.resid() for pmdarima\n",
    "    fitted_values = fit.fittedvalues() # Use fit.fittedvalues()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "    # 1. Time Series Plot of Residuals\n",
    "    axes[0, 0].plot(residuals)\n",
    "    axes[0, 0].set_title('Residuals over Time')\n",
    "    axes[0, 0].set_xlabel('Time')  # More general x-axis label\n",
    "    axes[0, 0].set_ylabel('Residuals')\n",
    "    axes[0, 0].grid(True)\n",
    "\n",
    "    # 2. Histogram of Residuals\n",
    "    axes[0, 1].hist(residuals, bins=bins)\n",
    "    axes[0, 1].set_title('Histogram of Residuals')\n",
    "    axes[0, 1].set_xlabel('Residuals')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "    # 3. Q-Q Plot\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "    axes[1, 0].set_title('Q-Q Plot of Residuals')\n",
    "\n",
    "    # 4. ACF Plot\n",
    "    plot_acf(residuals, lags=lags, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Autocorrelation Function (ACF)')\n",
    "\n",
    "    # 5. Residuals vs. Fitted Values\n",
    "    axes[2, 0].scatter(fitted_values, residuals)\n",
    "    axes[2, 0].set_title('Residuals vs. Fitted Values')\n",
    "    axes[2, 0].set_xlabel('Fitted Values')\n",
    "    axes[2, 0].set_ylabel('Residuals')\n",
    "    axes[2, 0].grid(True)\n",
    "\n",
    "    fig.delaxes(axes[2, 1])  # Remove the empty subplot\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_arima_residuals(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intervals\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_df['Date'], train_df['Revenue Losses'], label='Actual Train')\n",
    "plt.plot(test_df['Date'], test_df['Revenue Losses'], label='Actual Test')\n",
    "plt.plot(test_df['Date'], forecast_values, label='Forecast', color='red')  # Original forecast\n",
    "\n",
    "plt.fill_between(test_df['Date'], lower_series, upper_series, color='gray', alpha=0.2, label=f'95% Prediction Interval')\n",
    "\n",
    "plt.title('ARIMA Prediction Intervals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['Revenue Losses'], label=\"Actual\")\n",
    "plt.plot(forecast_values, label=\"Holt-Winters Forecast\")\n",
    "# Title of Revenue Losses Forecast\n",
    "plt.title('Revenue Losses Forecast')\n",
    "# Format y axis as thousands of dollars\n",
    "plt.gca().yaxis.set_major_formatter((lambda x, _: f'${int(x/1000)}K'))\n",
    "# Format x axis as dates - add x number of days to first date in data, format as date\n",
    "plt.gca().xaxis.set_major_formatter((lambda x, _: (df['Date'][0] + pd.DateOffset(days=int(x))).strftime('%Y-%m-%d')))\n",
    "# Rotate x axis labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Check MAE, RMSE on test set\n",
    "mae = mean_absolute_error(test_df['Revenue Losses'], forecast_values)\n",
    "rmse = root_mean_squared_error(test_df['Revenue Losses'], forecast_values)\n",
    "print('MAE:', mae)\n",
    "print('RMSE:', rmse)\n",
    "# Also compute MAPE for reporting\n",
    "mape = np.mean(np.abs((test_df['y'] - forecast['yhat'][-len(test_df):]) / test_df['y'])) * 100\n",
    "print('MAPE:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-day seasonal naive forecast for comparison\n",
    "last_7 = list(train_df['y'][-7:])\n",
    "seasonal_naive_forecast = [last_7[i % 7] for i in range(len(test_df))]\n",
    "# Set index of dates to be that of test_df\n",
    "seasonal_naive_forecast_df = pd.DataFrame(seasonal_naive_forecast, index=test_df.index, columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot with seasonal naive forecast\n",
    "plt.plot(test_df['Revenue Losses'], label=\"Actual\")\n",
    "plt.plot(forecast_values, label=\"ARIMA Forecast\")\n",
    "# Seasonal naive forecast\n",
    "plt.plot(seasonal_naive_forecast_df['y'], label=\"Seasonal Naive Forecast\")\n",
    "# Add prophet prediction intervals\n",
    "plt.fill_between(test_df.index, lower_series, upper_series, color='gray', alpha=0.2, label='95% Prediction Interval')\n",
    "# Title of Revenue Losses Forecast\n",
    "plt.title('Revenue Losses Forecast')\n",
    "# Format y axis as thousands of dollars\n",
    "plt.gca().yaxis.set_major_formatter((lambda x, _: f'${int(x/1000)}K'))\n",
    "# Format x axis as dates - add x number of days to first date in data, format as date\n",
    "plt.gca().xaxis.set_major_formatter((lambda x, _: (df['ds'][0] + pd.DateOffset(days=int(x))).strftime('%Y-%m-%d')))\n",
    "# Rotate x axis labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# MAE, RMSE, MAPE for seasonal naive forecast\n",
    "mae = mean_absolute_error(test_df['y'], seasonal_naive_forecast)\n",
    "rmse = root_mean_squared_error(test_df['y'], seasonal_naive_forecast)\n",
    "print('Seasonal Naive MAE:', mae)\n",
    "print('Seasonal Naive RMSE:', rmse)\n",
    "mape = np.mean(np.abs((test_df['y'] - seasonal_naive_forecast) / test_df['y'])) * 100\n",
    "print('Seasonal Naive MAPE:', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcbroken-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
